{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Processed Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN-type Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(training_dataset) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39m# Generate random noise and text input\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(size\u001b[39m=\u001b[39m(batch_size, latent_dim))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaron68lee/Documents/Coding-Projects/ForgeNet/model.ipynb#X14sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         text_input \u001b[39m=\u001b[39m get_random_text_input(batch_size)  \u001b[39m# Custom function to get text input\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Step 1: Data collection - Prepare your labeled dataset\n",
    "\n",
    "# Step 2: Preprocessing - Perform necessary image preprocessing steps\n",
    "\n",
    "# Step 3: Image-to-text conversion - Use an OCR library to extract text from images\n",
    "\n",
    "# Step 4: Model selection\n",
    "latent_dim = 100\n",
    "text_dim = 128\n",
    "image_dim = 28 \n",
    "\n",
    "# Generator model\n",
    "generator_input = layers.Input(shape=(latent_dim + text_dim,))\n",
    "x = layers.Dense(256)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(1024)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "generator_output = layers.Dense(image_dim, activation='tanh')(x)\n",
    "generator = tf.keras.Model(generator_input, generator_output)\n",
    "\n",
    "# Discriminator model\n",
    "discriminator_input = layers.Input(shape=(image_dim,))\n",
    "x = layers.Dense(512)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "discriminator = tf.keras.Model(discriminator_input, discriminator_output)\n",
    "\n",
    "# Combined model\n",
    "gan_input = layers.Input(shape=(latent_dim + text_dim,))\n",
    "generated_image = generator(gan_input)\n",
    "discriminator.trainable = False\n",
    "gan_output = discriminator(generated_image)\n",
    "gan = tf.keras.Model(gan_input, gan_output)\n",
    "\n",
    "# Step 5: Data preparation\n",
    "# Prepare your training dataset with input text and corresponding preprocessed images\n",
    "\n",
    "# Step 6: Model training\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(len(training_dataset) // batch_size):\n",
    "        # Generate random noise and text input\n",
    "        noise = np.random.normal(size=(batch_size, latent_dim))\n",
    "        text_input = get_random_text_input(batch_size)  # Custom function to get text input\n",
    "        \n",
    "        # Generate images from noise and text input\n",
    "        generated_images = generator.predict([noise, text_input])\n",
    "\n",
    "        # Combine real and generated images for the discriminator\n",
    "        real_images = get_real_images(batch_size)  # Custom function to get real images\n",
    "        combined_images = np.concatenate([real_images, generated_images])\n",
    "\n",
    "        # Labels for real and generated images\n",
    "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "        labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator(combined_images)\n",
    "            discriminator_loss = loss(labels, predictions)\n",
    "        grads = tape.gradient(discriminator_loss, discriminator.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        # Train the generator (via the gan model)\n",
    "        noise = np.random.normal(size=(batch_size, latent_dim))\n",
    "        text_input = get_random_text_input(batch_size)  # Custom function to get text input\n",
    "        labels = np.ones((batch_size, 1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = generator([noise, text_input])\n",
    "            predictions = discriminator(generated_images)\n",
    "            generator_loss = loss(labels, predictions)\n",
    "        grads = tape.gradient(generator_loss, generator.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "\n",
    "# Step 7: Model evaluation - Assess the performance of the trained model\n",
    "\n",
    "# Step 8: Model fine-tuning - Fine-tune the model if necessary\n",
    "\n",
    "# Step 9: Generation - Generate new images based on input text\n",
    "input_text = \"Hello, World!\"\n",
    "noise = np.random.normal(size=(1, latent_dim))\n",
    "text_input = preprocess_text(input_text)  # Custom function to preprocess input text\n",
    "generated_image = generator.predict([noise, text_input])\n",
    "# Display or save the generated image\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-type Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128  # Dimensionality of the latent space\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "\n",
    "# Decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "# Variational Autoencoder\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed\n",
    "\n",
    "vae = VAE(encoder, decoder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(inputs, outputs):\n",
    "    reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "    reconstruction_loss *= 28 * 28  # Image size\n",
    "    return reconstruction_loss\n",
    "\n",
    "def kl_divergence_loss(z_mean, z_log_var):\n",
    "    # Kullback-Leiber Divergence Loss\n",
    "    kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "    return kl_loss\n",
    "\n",
    "def vae_loss(inputs, outputs, z_mean, z_log_var):\n",
    "    reconstruction = reconstruction_loss(inputs, outputs)\n",
    "    kl_divergence = kl_divergence_loss(z_mean, z_log_var)\n",
    "    return reconstruction + kl_divergence\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "vae.compile(optimizer, loss=vae_loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.fit(dataset, epochs=10, batch_size=64)\n",
    "\n",
    "random_latent_vectors = tf.random.normal(shape=(num_samples, latent_dim))\n",
    "generated_images = decoder(random_latent_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_saved_model = '/content/scrabble-gan/res/out/big_ac_gan/model/generator_' + str(epochs)\n",
    "\n",
    "# number of samples to generate\n",
    "n_samples = 10\n",
    "# your sample string\n",
    "sample_string = 'machinelearning'\n",
    "\n",
    "# load trained model\n",
    "imported_model = tf.saved_model.load(path_to_saved_model)\n",
    "\n",
    "# inference loop\n",
    "for idx in range(1):\n",
    "  fake_labels = []\n",
    "  words = [sample_string] * 10\n",
    "  noise = tf.random.normal([n_samples, latent_dim])\n",
    "  \n",
    "  # encode words\n",
    "  for word in words:\n",
    "    fake_labels.append([char_vec.index(char) for char in word])\n",
    "  fake_labels = np.array(fake_labels, np.int32)\n",
    "\n",
    "  # run inference process\n",
    "  predictions = imported_model([noise, fake_labels], training=False)\n",
    "  # transform values into range [0, 1]\n",
    "  predictions = (predictions + 1) / 2.0\n",
    "\n",
    "  # plot results\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(10, 1, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    # plt.text(0, -1, \"\".join([char_vec[label] for label in fake_labels[i]]))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "year = 1939\n",
    "print(2023 - year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
